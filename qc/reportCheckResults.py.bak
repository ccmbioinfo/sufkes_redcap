import os, sys
import csv

from Color import Color
from formatStrings import formatFieldName, formatDAGName

def fancyNewLine(string):
    return "\n"+string * 80

def combineCheckReports(checklist, out_dir, dags):
    """This script looks for site-specific reports in the output directory and combines all of the 
    checks into a single document."""

    # THIS IS NOT WELL ORGANIZED. PROBABLY THE BEST WAY IS IF THE CHECK DRIVER ONLY GENERATES THE LIST
    # OF CHECK RESULTS, AND ANOTHER FUNCTION GENERATES REPORTS BASED ON THOSE.

    ## DAG-Instrument-Count report
    master_report_name = os.path.join(out_dir, "all_checks.csv")

    # Build list of check report paths.
    report_path_list = []
    for check in checklist:
        report_path = os.path.join(os.path.join(out_dir, check.name+".csv"))
        if os.path.exists(report_path):
            report_path_list.append(report_path)

    # Append check reports to master report.
    if (len(report_path_list) > 0):
        with open(master_report_name, 'wb') as dest_csv:
            dest_writer = csv.writer(dest_csv, delimiter=",")
            for report_path in report_path_list:
                with open(report_path, 'rb') as src_csv:
                    src_reader = csv.reader(src_csv, delimiter=",")
                    for row in src_reader:
                        dest_writer.writerow(row)
                    dest_writer.writerow([""])

    ## DAG-Subject-Instrument-Field report
    # Loop over all DAGs.
    for dag in dags:
        dag_name = formatDAGName(dag) # format DAG name (turn blank DAG into "UNASSIGNED")
        master_site_report_name = os.path.join(os.path.join(out_dir, "site-form-field"), "all_checks_"+dag_name+".csv")

        # Build list of check report paths.
        report_path_list = []
        for check in checklist:
            report_path = os.path.join(os.path.join(out_dir, "site-form-field"), check.name+"-"+dag_name+".csv")
            if os.path.exists(report_path):
                report_path_list.append(report_path)
                
        # Append check reports to master report for each site.
        if (len(report_path_list) > 0):
            with open(master_site_report_name, 'wb') as dest_csv:
                dest_writer = csv.writer(dest_csv, delimiter=",")
                for report_path in report_path_list:
                    with open(report_path, 'rb') as src_csv:
                        src_reader = csv.reader(src_csv, delimiter=",")
                        for row in src_reader:
                            dest_writer.writerow(row)
                        dest_writer.writerow([""])
    return


def reportCheckResults(elements_to_check, bad_elements, check, out_dir, def_field, project_longitudinal, project_repeating, events, forms, form_repetition_map, metadata, records, record_id_map, dags_used, dags, dag_record_map): # WRITTEN FOR A SINGLE-FIELD CHECK; EXTEND TO MULTI-FIELD CHECKS.
    # Print a description of the check being performed.
    print fancyNewLine("#")
    print "Performing check:", check.description
    
#    # Simple report to stdout. Useful for testing purposes.
#    print fancyNewLine("-")
#    print "Basic report (field-count)"
#    count_lim = 12 # Max number of records to show for each. 
#    if (not project_longitudinal) and (not project_repeating):
#        for field_name, field in metadata.iteritems():
#            count = 0
#            for bad_element in bad_elements:
#                bad_row_index = bad_element[0]
#                bad_field_name = bad_element[1]
#                bad_field = metadata[bad_field_name]
#                if (bad_field_name == field_name):
#                    if (count == 0):
#                        print
#                        print "Field:", formatFieldName(field_name, metadata)
#                        print "Form:", field.form_name                    
#                    if (count < count_lim):
#                        print records[bad_row_index][def_field]
#                    elif (count == count_lim):
#                        print records[bad_row_index][def_field]
#                    elif (count == count_lim + 1):
#                        print "..."
#                    count += 1
#            if (count > 0):
#                print "Count:", count
#    elif (project_longitudinal) and (not project_repeating):
#        for field_name, field in metadata.iteritems():
#            for event in field.events_containing_field:
#                count = 0
#                for bad_element in bad_elements:
#                    bad_row_index = bad_element[0]
#                    bad_field_name = bad_element[1]
#                    bad_field = metadata[bad_field_name]
#                    bad_event = records[bad_row_index]["redcap_event_name"]
#                    if (bad_field_name == field_name) and (bad_event == event):
#                        if (count == 0):
#                            print 
#                            print "Field:", formatFieldName(field_name, metadata)
#                            print "Form:", field.form_name
#                            print "Event:", event
#                        if (count <= count_lim):
#                            print records[bad_row_index][def_field]
#                        elif (count == count_lim + 1):
#                            print "..."
#                        count += 1
#                if (count > 0):
#                    print "Count:", count
#    elif (not project_longitudinal) and (project_repeating):
#        for field_name, field in metadata.iteritems():
#            count = 0
#            for bad_element in bad_elements:
#                bad_row_index = bad_element[0]
#                bad_field_name = bad_element[1]
#                bad_field = metadata[bad_field_name]
#                bad_instance = records[bad_row_index]["redcap_repeat_instance"]
#                if (bad_field_name == field_name):
#                    if (count == 0):
#                        print
#                        print "Field:", formatFieldName(field_name, metadata)
#                        print "Form:", field.form_name
#                    if (count <= count_lim):
#                        print records[bad_row_index][def_field]+(" (instance "+str(bad_instance)+")" if bad_instance != "" else "")
#                    elif (count == count_lim + 1):
#                        print "..."
#                    count += 1
#            if (count > 0):
#                print "Count:", count
#    else:
#        for field_name, field in metadata.iteritems():
#            for event in field.events_containing_field:
#                count = 0
#                for bad_element in bad_elements:
#                    bad_row_index = bad_element[0]
#                    bad_field_name = bad_element[1]
#                    bad_field = metadata[bad_field_name]
#                    bad_event = records[bad_row_index]["redcap_event_name"]
#                    bad_instance = records[bad_row_index]["redcap_repeat_instance"]
#                    if (bad_field_name == field_name) and (bad_event == event):
#                        if (count == 0):
#                            print 
#                            print "Field:", formatFieldName(field_name, metadata)
#                            print "Form:", field.form_name
#                            print "Event:", event
#                        if (count <= count_lim):
#                            print records[bad_row_index][def_field]+(" (instance "+str(bad_instance)+")" if bad_instance != "" else "")
#                        elif (count == count_lim + 1):
#                            print "..."
#                        count += 1
#                if (count > 0):
#                    print "Count:", count
    # Whole-row checks, intra-row (e.g. invalid event, form, instance for row).
    # report: 1 report
    # rows: row indices in records
    # columns: None
    if (check.whole_row_check) and (not check.inter_row):
        print fancyNewLine("-")
        print "Whole-row check report; intra-row"

        # Open report file handle
        report_filepath = os.path.join(out_dir, check.name+".csv")
        report_handle = open(report_filepath, 'w')
        report_writer = csv.writer(report_handle, delimiter=",")
        
        # Write description of check at top of spreadsheet.
        zeroth_row = ["Check" , check.description]
        report_writer.writerow(zeroth_row)

        # Write first row of report spreadsheet.
        first_row = ["row index"]
        report_writer.writerow(first_row)

        # Add problematic row indices to report.
        for element in bad_elements:
            row_index = element[0]
            new_row = [row_index]
            report_writer.writerow(new_row)
        report_handle.close()


    # Whole-row checks, inter-row (e.g. duplicate records, invalid rows)
    # report: 1 report
    # rows: row indices in records
    # columns: row indices of other records if specified (e.g. of duplicate record)
    if (check.whole_row_check) and (check.inter_row):
        print fancyNewLine("-")
        print "Whole-row check report; inter-row"

        # Open report file handle
        report_filepath = os.path.join(out_dir, check.name+".csv")
        report_handle = open(report_filepath, 'w')
        report_writer = csv.writer(report_handle, delimiter=",")
        
        # Write description of check at top of spreadsheet.
        zeroth_row = ["Check" , check.description]
        report_writer.writerow(zeroth_row)

        # Write first row of report spreadsheet.
        first_row = ["row index", "other row index"]
        report_writer.writerow(first_row)

        # Add problematic row indices to report.
        for element in bad_elements:
            row_index = element[0]
            other_row_indices = element[1] # e.g. row indices of duplicate records.
            new_row = [row_index]
            new_row.extend(other_row_indices)
            
            report_writer.writerow(new_row)
        report_handle.close()
            


    # DAG-Instrument-Count report
    # report: 1 report
    # rows: site
    # columns: instrument
    # entries: count

    if dags_used and (not check.whole_row_check):
        print fancyNewLine("-")
        print "DAG-instrument-count Report"

        # Open report file handle. 
        report_filepath = os.path.join(out_dir, check.name+".csv")
        report_handle = open(report_filepath, 'w')
        report_writer = csv.writer(report_handle, delimiter=",")

        # Write description of check at top of spreadsheet
        zeroth_row = ["Check", check.description]
        report_writer.writerow(zeroth_row)

        # Write first row of report spreadsheet
        first_row = ["Site"]
        for form in forms:
            form_label = form["instrument_label"]
            first_row.append(form_label)
        first_row.append("Error rate (# errors found / # times check performed)")
        first_row.append("Subject error rate (# subjects with errors / # subjects in DAG)")
        report_writer.writerow(first_row)

        for dag in dags:
            num_errors_dag = 0
            new_row = [formatDAGName(dag)]
            for form in forms:
                form_name = form["instrument_name"] # Internal instrument name (e.g. 'patient_information')
                form_label = form["instrument_label"] # Online-displayed instrument name (e.g. 'Patient Information')
                num_errors_dag_form = 0
                for bad_element in bad_elements:                
                    bad_row_index = bad_element[0]
                    bad_field_name = bad_element[1]
                    bad_field = metadata[bad_field_name]
                    bad_dag = records[bad_row_index]["redcap_data_access_group"]
                    bad_form_name = bad_field.form_name
    
                    if bad_dag == dag:
                        if bad_form_name == form_name:
                            num_errors_dag_form += 1
                            num_errors_dag += 1
                if (num_errors_dag_form != 0):
                    print
                    print Color.blue+"DAG:"+Color.end, dag
                    print Color.blue+"form:"+Color.end, form_label
                    print Color.blue+"count:"+Color.end, num_errors_dag_form
                new_row.append(num_errors_dag_form)

            # Calculate the error rate for the current dag.
            num_checks_performed_dag = 0 # Number of times this check was performed for this DAG.
            for element in elements_to_check:
                element_row_index = element[0]
                element_dag = records[element_row_index]["redcap_data_access_group"]
                if (dag == element_dag):
                    num_checks_performed_dag += 1
            if (num_checks_performed_dag == 0):
                error_rate = "N/A"
                new_row.append(error_rate)
            else:
                error_rate = float(num_errors_dag)/float(num_checks_performed_dag)
                new_row.append("{:.2f}".format(error_rate*100)+"%"+" ("+str(num_errors_dag)+"/"+str(num_checks_performed_dag)+")")

            # Calculate the subject-wise error rate (number of patients with error in DAG/number of patients in DAG -- not the number checked)
            num_bad_records_in_dag = 0
            for record_id in dag_record_map[dag]["record_ids"]:
                for bad_element in bad_elements:
                    bad_row_index = bad_element[0]
                    bad_record_id = records[bad_row_index][def_field]
                    if (bad_record_id == record_id):
                        num_bad_records_in_dag += 1
                        break
            subject_wise_error_rate = float(num_bad_records_in_dag)/float(dag_record_map[dag]["num_records"])
            new_row.append("{:.2f}".format(subject_wise_error_rate*100)+"%"+" ("+str(num_bad_records_in_dag)+"/"+str(dag_record_map[dag]["num_records"])+")")
            
            # Add row for current DAG.
            report_writer.writerow(new_row)

        report_handle.close() # Close the report file handle.


    # DAG-Subject-Instrument-Field report
    # report: site
    # rows: subject
    # columns: instrument
    # entries: fields
    if dags_used and project_longitudinal and project_repeating and (not check.whole_row_check):
        print fancyNewLine("-")
        print "DAG-subject-instrument-field Report:"
        for dag in dags:
            dag_errors_found = False # Only create csv file if errors are found for dag.
            
            # Create a subdirectory to store the site-specific reports.
            out_sub_dir = os.path.join(out_dir, "site-form-field")
            if (not os.path.isdir(out_sub_dir)):
                os.mkdir(out_sub_dir)
    
            # Write column headers of report spreadsheet
            first_row = ["Patient"]
            
            for form in forms:
                form_name = form["instrument_name"]
                form_label = form["instrument_label"]
                if (len(form_repetition_map[form_name]["events"]) > 1): # Specify event if form lives in multple events
                    for event in form_repetition_map[form_name]["events"]:
                        column_header = form_label+" ("+events[event]["event_name"]+")"
                        first_row.append(column_header)
                else: # If form lives in only one event, do not specify event.
                    first_row.append(form_label)
            # Add success rate column if check is performed multiple times for a single record.
            first_row.append("Error rate (# errors found / # times check performed)")

            # Write the rest of the row containing actual data.
            for record_id in dag_record_map[dag]["record_ids"]: # each iteration is a row (if errors are found).
                num_errors_record = 0 # number of errors found for this record
                new_row = [record_id]
                for form in forms:
                    form_name = form["instrument_name"]
                    form_label = form["instrument_label"]
                    
                    for event in form_repetition_map[form_name]["events"]: # each iteration corresponds to a column
                        bad_vars = []
                        for bad_element in bad_elements:
                            bad_row_index = bad_element[0]
                            bad_field_name = bad_element[1]
                            bad_field = metadata[bad_field_name]
                            bad_record_id = records[bad_row_index][def_field]
                            bad_dag = records[bad_row_index]["redcap_data_access_group"]
                            bad_event = records[bad_row_index]["redcap_event_name"]
                            bad_instance = records[bad_row_index]["redcap_repeat_instance"]
                            bad_form_name = bad_field.form_name
                            if bad_dag == dag:
                                if bad_record_id == record_id:
                                    if bad_form_name == form_name:
                                        if bad_event == event:
                                            if (not check.specify_fields):
                                                bad_var = formatFieldName(bad_field_name,  metadata)
                                            else:
#                                                if (len(check.target_fields) > 1):
#                                                    bad_var = "("
#                                                    for var in check.target_fields:
#                                                        bad_var += formatFieldName(var, metadata)+", "
#                                                    bad_var = bad_var[:-2] # strip last comma and space
#                                                    bad_var += ")"
                                                bad_var = "X"
                                            if (bad_instance != ""): # if bad entry is in a repeating field, specify instance.
                                                bad_var += " (#"+str(bad_instance)+")"
                                            bad_vars.append(bad_var)
                                            num_errors_record += 1
                        bad_vars_string = ""
                        if (len(bad_vars) > 0):
                            print
                            print Color.blue+"DAG:"+Color.end, dag
                            print Color.blue+"Record:"+Color.end, record_id
                            print Color.blue+"Event:"+Color.end, event
                            print Color.blue+"Form:"+Color.end, form_label
                            print Color.blue+"Problematic fields:"+Color.end
                            for bad_var in bad_vars:
                                print bad_var

                            # Create a string of the bad vars for this (patient, form) to put in spreadsheet.
                            for bad_var_index in range(len(bad_vars)):
                                bad_var = bad_vars[bad_var_index]
                                if (not bad_var_index == len(bad_vars)-1):
                                    bad_vars_string += bad_var+", "
                                else:
                                    bad_vars_string += bad_var
                        new_row.append(bad_vars_string)
                
                # Add the new row to the report 
#                new_row_empty = True # 
#                for col in new_row[1:]:
#                    if (not col == ""):
#                        new_row_empty = False
#                        break
#                if (not new_row_empty): # if error was found for current record
                if (num_errors_record > 0):
#                    # If check is performed multiple times for a single record ID, calculate the success rate.
#                    if (not check.specify_fields):
                    num_checks_performed_record = 0
                    for element in elements_to_check:
                        element_row_index = element[0]
                        element_record_id = records[element_row_index][def_field]
                        if (record_id == element_record_id):
                            num_checks_performed_record += 1
                    # Write success rate to last column.
                    success_rate_record = float(num_errors_record)/float(num_checks_performed_record)
                    new_row.append("{:.2f}".format(success_rate_record*100)+"%"+" ("+str(num_errors_record)+"/"+str(num_checks_performed_record)+")")
                    if (not dag_errors_found): # if this is the first error found for this DAG
                        dag_errors_found = True

                        # Open report file handle.
                        formatted_dag = formatDAGName(dag)
                        report_filepath = os.path.join(out_sub_dir, check.name+"-"+formatted_dag+".csv")
                        report_handle = open(report_filepath, 'w')
                        report_writer = csv.writer(report_handle, delimiter=",")

                        # Write description of check at top of spreadsheet
                        zeroth_row = ["Check", check.description]
                        report_writer.writerow(zeroth_row)

                        # Write column headers.
                        report_writer.writerow(first_row)
                    
                    # Add row for current record for which an error was found.
                    report_writer.writerow(new_row)

            if dag_errors_found: # Close file handle if errors were found for current dag.
                report_handle.close()
    return
